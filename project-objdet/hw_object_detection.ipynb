{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55502/101224089.py:6: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import os\n",
    "import random\n",
    "from argparse import ArgumentParser\n",
    "from pathlib import Path\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "import lightning as L\n",
    "import numpy as np\n",
    "import torch\n",
    "from odection import (\n",
    "    SSD,\n",
    "    CocoDataset,\n",
    "    Loss,\n",
    "    ResNet,\n",
    "    SSDTransformer,\n",
    "    collate_fn,\n",
    ")\n",
    "from odection.utils import Encoder, coco_classes, generate_dboxes\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard.writer import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L.fabric.utilities.seed.seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BS = 128\n",
    "LR = 3e-4\n",
    "# LR = LR * (BS / 32)\n",
    "EPOCHS = 100\n",
    "NUM_WORKERS = 4\n",
    "MULTISTEP = [43, 54]\n",
    "NMS_THRESHOLD = 0.5\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 0.0005\n",
    "\n",
    "DATA_PATH = Path(\"data/\")\n",
    "LOG_PATH = Path(\"logs/tensorboard/ssd\")\n",
    "SAVE_PATH = Path(\"models\")\n",
    "CHECKPOINT_PATH = SAVE_PATH / \"ssd-checkpoint.pth\"\n",
    "\n",
    "LOG_PATH.mkdir(parents=True, exist_ok=True)\n",
    "SAVE_PATH.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_date = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "writer = SummaryWriter(f\"{LOG_PATH}/{str_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16-bit Automatic Mixed Precision (AMP)\n"
     ]
    }
   ],
   "source": [
    "# torch.set_float32_matmul_precision(\"high\")\n",
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "fabric = L.Fabric(\n",
    "    accelerator=\"auto\",\n",
    "    devices=\"auto\",\n",
    "    strategy=\"dp\",\n",
    "    precision=\"16-mixed\",\n",
    "    # loggers=SummaryWriter(f\"{log_path}/{str_date}\")\n",
    ")\n",
    "fabric.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=6.09s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.18s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "dboxes = generate_dboxes(model=\"ssd\")\n",
    "\n",
    "train_params = {\n",
    "    \"batch_size\": BS,\n",
    "    \"shuffle\": True,\n",
    "    \"drop_last\": False,\n",
    "    \"num_workers\": NUM_WORKERS,\n",
    "    \"collate_fn\": collate_fn,\n",
    "}\n",
    "valid_params = {\n",
    "    \"batch_size\": BS,\n",
    "    \"shuffle\": False,\n",
    "    \"drop_last\": False,\n",
    "    \"num_workers\": NUM_WORKERS,\n",
    "    \"collate_fn\": collate_fn,\n",
    "}\n",
    "train_set = CocoDataset(\n",
    "    DATA_PATH,\n",
    "    2017,\n",
    "    \"train\",\n",
    "    SSDTransformer(dboxes, (300, 300), val=False),\n",
    ")\n",
    "test_set = CocoDataset(\n",
    "    DATA_PATH,\n",
    "    2017,\n",
    "    \"val\",\n",
    "    SSDTransformer(dboxes, (300, 300), val=True),\n",
    ")\n",
    "train_loader = fabric.setup_dataloaders(\n",
    "    DataLoader(\n",
    "        train_set,\n",
    "        **train_params,\n",
    "    )\n",
    ")\n",
    "test_loader = fabric.setup_dataloaders(\n",
    "    DataLoader(\n",
    "        test_set,\n",
    "        **valid_params,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/lib/python3.10/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d822bc28d461474689813adc906324a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/925 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c1818ea277a4fffb6edcb08c34b0336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/925 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "118449a2acdc402a844023501d28d141",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/925 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73bd3853d297456da3da4b16900be5ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/925 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 40\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[39m# loss.backward()\u001b[39;00m\n\u001b[1;32m     39\u001b[0m     fabric\u001b[39m.\u001b[39mbackward(loss)\n\u001b[0;32m---> 40\u001b[0m     optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     41\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     42\u001b[0m scheduler\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m/venv/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:69\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m instance\u001b[39m.\u001b[39m_step_count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     68\u001b[0m wrapped \u001b[39m=\u001b[39m func\u001b[39m.\u001b[39m\u001b[39m__get__\u001b[39m(instance, \u001b[39mcls\u001b[39m)\n\u001b[0;32m---> 69\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/venv/lib/python3.10/site-packages/lightning/fabric/wrappers.py:73\u001b[0m, in \u001b[0;36m_FabricOptimizer.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     optimizer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\n\u001b[0;32m---> 73\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_strategy\u001b[39m.\u001b[39;49moptimizer_step(\n\u001b[1;32m     74\u001b[0m     optimizer,\n\u001b[1;32m     75\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m     76\u001b[0m )\n\u001b[1;32m     77\u001b[0m \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_callbacks:\n\u001b[1;32m     78\u001b[0m     hook \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(callback, \u001b[39m\"\u001b[39m\u001b[39mon_after_optimizer_step\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/venv/lib/python3.10/site-packages/lightning/fabric/strategies/strategy.py:169\u001b[0m, in \u001b[0;36mStrategy.optimizer_step\u001b[0;34m(self, optimizer, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimizer_step\u001b[39m(\n\u001b[1;32m    159\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    160\u001b[0m     optimizer: Optimizable,\n\u001b[1;32m    161\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    162\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    163\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Performs the actual optimizer step.\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \n\u001b[1;32m    165\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[39m        optimizer: the optimizer performing the step\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[39m        **kwargs: Any extra arguments to ``optimizer.step``\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 169\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprecision\u001b[39m.\u001b[39;49moptimizer_step(optimizer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/venv/lib/python3.10/site-packages/lightning/fabric/plugins/precision/amp.py:89\u001b[0m, in \u001b[0;36mMixedPrecision.optimizer_step\u001b[0;34m(self, optimizer, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAMP and the LBFGS optimizer are not compatible.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     88\u001b[0m \u001b[39m# note: the scaler will skip the `optimizer.step` if nonfinite gradients are found\u001b[39;00m\n\u001b[0;32m---> 89\u001b[0m step_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscaler\u001b[39m.\u001b[39;49mstep(optimizer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     90\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscaler\u001b[39m.\u001b[39mupdate()\n\u001b[1;32m     91\u001b[0m \u001b[39mreturn\u001b[39;00m step_output\n",
      "File \u001b[0;32m/venv/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:374\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munscale_(optimizer)\n\u001b[1;32m    372\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(optimizer_state[\u001b[39m\"\u001b[39m\u001b[39mfound_inf_per_device\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 374\u001b[0m retval \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_opt_step(optimizer, optimizer_state, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    376\u001b[0m optimizer_state[\u001b[39m\"\u001b[39m\u001b[39mstage\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m OptState\u001b[39m.\u001b[39mSTEPPED\n\u001b[1;32m    378\u001b[0m \u001b[39mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m/venv/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:289\u001b[0m, in \u001b[0;36mGradScaler._maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_maybe_opt_step\u001b[39m(\u001b[39mself\u001b[39m, optimizer, optimizer_state, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    288\u001b[0m     retval \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39msum\u001b[39;49m(v\u001b[39m.\u001b[39;49mitem() \u001b[39mfor\u001b[39;49;00m v \u001b[39min\u001b[39;49;00m optimizer_state[\u001b[39m\"\u001b[39;49m\u001b[39mfound_inf_per_device\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mvalues()):\n\u001b[1;32m    290\u001b[0m         retval \u001b[39m=\u001b[39m optimizer\u001b[39m.\u001b[39mstep(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    291\u001b[0m     \u001b[39mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m/venv/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:289\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_maybe_opt_step\u001b[39m(\u001b[39mself\u001b[39m, optimizer, optimizer_state, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    288\u001b[0m     retval \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39msum\u001b[39m(v\u001b[39m.\u001b[39;49mitem() \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m optimizer_state[\u001b[39m\"\u001b[39m\u001b[39mfound_inf_per_device\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mvalues()):\n\u001b[1;32m    290\u001b[0m         retval \u001b[39m=\u001b[39m optimizer\u001b[39m.\u001b[39mstep(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    291\u001b[0m     \u001b[39mreturn\u001b[39;00m retval\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "encoder = Encoder(dboxes)\n",
    "model = SSD(backbone=ResNet(), num_classes=len(coco_classes))\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=LR,\n",
    ")\n",
    "model, optimizer = fabric.setup(model, optimizer)\n",
    "scheduler = MultiStepLR(optimizer=optimizer, milestones=MULTISTEP, gamma=0.1)\n",
    "criterion = Loss(dboxes, device=fabric.device)\n",
    "\n",
    "if CHECKPOINT_PATH.is_file():\n",
    "    checkpoint = torch.load(CHECKPOINT_PATH)\n",
    "    first_epoch = checkpoint[\"epoch\"] + 1\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "    scheduler.load_state_dict(checkpoint[\"scheduler\"])\n",
    "else:\n",
    "    first_epoch = 0\n",
    "\n",
    "for i_epoch, epoch in enumerate(range(first_epoch, EPOCHS)):\n",
    "    model.train()\n",
    "    num_iter_per_epoch = len(train_loader)\n",
    "    progress_bar = tqdm(train_loader)\n",
    "    for i, (img, _, _, gloc, glabel) in enumerate(progress_bar):\n",
    "        ploc, plabel = model(img)\n",
    "        ploc, plabel = ploc.float(), plabel.float()\n",
    "        gloc = gloc.transpose(1, 2).contiguous()\n",
    "        loss = criterion(ploc, plabel, gloc, glabel)\n",
    "        progress_bar.set_description(f\"Epoch: {epoch + 1}. Loss: {loss.item():.5f}\")\n",
    "        writer.add_scalar(\"Train/Loss\", loss.item(), epoch * num_iter_per_epoch + i)\n",
    "        # loss.backward()\n",
    "        fabric.backward(loss)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    scheduler.step()\n",
    "\n",
    "    # evaluate(\n",
    "    #     model,\n",
    "    #     test_loader,\n",
    "    #     epoch,\n",
    "    #     writer,\n",
    "    #     encoder,\n",
    "    #     nms_threshold,\n",
    "    # )\n",
    "\n",
    "    checkpoint = {\n",
    "        \"epoch\": epoch,\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer\": optimizer.state_dict(),\n",
    "        \"scheduler\": scheduler.state_dict(),\n",
    "    }\n",
    "    torch.save(checkpoint, CHECKPOINT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
